{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransducerLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransducerLoss, self).__init__()\n",
    "        \n",
    "    def show_alignment(self, log_alpha):\n",
    "        plt.imshow(log_alpha.cpu().data.numpy().transpose(), origin=\"lower\"); plt.show()\n",
    "    \n",
    "    def compute_log_alpha_and_log_prob(self, encoder_out, decoder_out, y, blank):\n",
    "        \"\"\"\n",
    "        encoder_out: FloatTensor (T, #labels)\n",
    "        decoder_out: FloatTensor (U+1, #labels)\n",
    "        y: LongTensor (U,)\n",
    "        blank: int\n",
    "        \"\"\"\n",
    "        T = len(encoder_out)\n",
    "        U = len(y)\n",
    "        \n",
    "        log_alpha = torch.zeros(T, U+1) #[]\n",
    "        for t in range(T):\n",
    "            \n",
    "            for u in range(U + 1):\n",
    "                if u == 0:\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        log_alpha[t,u] = 0.\n",
    "                    \n",
    "                    else: #t > 0\n",
    "                        null_t_1_0 = encoder_out[t-1, blank] + decoder_out[0, blank]\n",
    "                        log_alpha[t,u] = log_alpha[t-1,u] + null_t_1_0\n",
    "                        \n",
    "                else: #u > 0\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        y_0_u_1 = encoder_out[t, y[u-1]] + decoder_out[u-1, y[u-1]]\n",
    "                        log_alpha[t,u] = log_alpha[t,u-1] + y_0_u_1\n",
    "                    \n",
    "                    else: #t > 0\n",
    "                        y_t_u_1 = encoder_out[t, y[u-1]] + decoder_out[u-1, y[u-1]]\n",
    "                        null_t_1_u = encoder_out[t-1, blank] + decoder_out[u, blank]\n",
    "                        \n",
    "                        log_alpha[t,u] = torch.logsumexp(torch.stack([\n",
    "                            log_alpha[t-1,u] + null_t_1_u,\n",
    "                            log_alpha[t,u-1] + y_t_u_1 \n",
    "                        ]), dim=0)\n",
    "        \n",
    "        null_T_1_U = encoder_out[T-1, blank] + decoder_out[U, blank]\n",
    "        log_p_y_x = log_alpha[T-1,U] + null_T_1_U\n",
    "        return log_alpha, log_p_y_x\n",
    "    \n",
    "    def forward(self,encoder_out,decoder_out,targets,input_lengths,target_lengths,reduction=\"none\",blank=0):\n",
    "        \"\"\"\n",
    "        encoder_out: FloatTensor (N, max(input_lengths), #labels)\n",
    "        decoder_out: FloatTensor (N, max(target_lengths)+1, #labels)\n",
    "        targets: LongTensor (N, max(target_lengths))\n",
    "        input_lengths: LongTensor (N)\n",
    "        target_lengths: LongTensor (N)\n",
    "        reduction: \"none\", \"avg\"\n",
    "        blank: int\n",
    "        \"\"\"\n",
    "        batch_size = len(input_lengths)\n",
    "        log_probs = []\n",
    "        for i in range(0, batch_size):\n",
    "            encoder_out_ = encoder_out[i, :input_lengths[i], :]\n",
    "            decoder_out_ = decoder_out[i, :target_lengths[i]+1, :]\n",
    "            y = targets[i, :target_lengths[i]]\n",
    "            log_alpha, log_p_y_x = self.compute_log_alpha_and_log_prob(encoder_out_, decoder_out_, y, blank)\n",
    "            self.show_alignment(log_alpha)\n",
    "            log_probs.append(log_p_y_x)\n",
    "        log_probs = torch.stack(log_probs)\n",
    "        return log_probs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0]])\n",
      "torch.Size([1, 4, 5])\n",
      "torch.Size([1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "num_labels = 5\n",
    "blank_index = num_labels-1 # last output = blank\n",
    "batch_size = 1\n",
    "pad = -1\n",
    "T = torch.LongTensor([4])\n",
    "U = torch.LongTensor([3])\n",
    "y = torch.randint(low=0,high=num_labels-1,size=(U[0],)).unsqueeze(0).long()\n",
    "print(y)\n",
    "\n",
    "encoder_out = torch.randn(batch_size, max(T), num_labels).log_softmax(2).detach().requires_grad_()\n",
    "decoder_out = torch.randn(batch_size, max(U)+1, num_labels).log_softmax(2).detach().requires_grad_()\n",
    "print(encoder_out.shape)\n",
    "print(decoder_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTCModel(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): ComputeFBANK()\n",
      "      (1): Conv(\n",
      "        (conv): Conv1d(80, 512, kernel_size=(11,), stride=(2,))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.125)\n",
      "      (3): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (4): RNNOutputSelect()\n",
      "      (5): Dropout(p=0.2, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (7): LeakyReLU(negative_slope=0.125)\n",
      "      (8): Downsample()\n",
      "      (9): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (10): RNNOutputSelect()\n",
      "      (11): Dropout(p=0.2, inplace=False)\n",
      "      (12): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (13): LeakyReLU(negative_slope=0.125)\n",
      "      (14): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (15): RNNOutputSelect()\n",
      "      (16): Dropout(p=0.2, inplace=False)\n",
      "      (17): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (18): LeakyReLU(negative_slope=0.125)\n",
      "      (19): Linear(in_features=512, out_features=1001, bias=True)\n",
      "      (20): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[26, 464, 33, 86, 115, 8, 86, 10, 9, 14, 3, 55, 20, 5, 379, 7, 81, 8, 10, 358, 8]\n",
      "HE COMPUTER COULDETERNALS ON IN THE KITCHENPLEE\n",
      "[26, 23, 464, 33, 86, 115, 38, 549, 5, 368, 3, 55, 20, 5, 379, 7, 81, 8, 10, 779]\n",
      "HEY COMPUTER COULD YOU TURN THE LIGHTS ON IN THE KITCHEN PLEASE\n",
      "torch.Size([1, 90, 1001])\n",
      "torch.Size([1, 21, 1001])\n",
      "tensor([[ 26,  23, 464,  33,  86, 115,  38, 549,   5, 368,   3,  55,  20,   5,\n",
      "         379,   7,  81,   8,  10, 779]])\n",
      "tensor([20])\n"
     ]
    }
   ],
   "source": [
    "# use pre-trained CTC model\n",
    "from models import CTCModel\n",
    "from data import read_config\n",
    "import sentencepiece as spm\n",
    "import soundfile as sf\n",
    "\n",
    "config = read_config(\"experiments/80_mel.cfg\")\n",
    "model = CTCModel(config=config).eval()\n",
    "model.load_pretrained(\"experiments/80_mel/training/best_model.pth\")\n",
    "print(model)\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(\"tokenizer_1000_tokens.model\")\n",
    "\n",
    "x,fs = sf.read(\"../end-to-end-SLU/test.wav\")\n",
    "x = torch.tensor(x).unsqueeze(0).float()\n",
    "\n",
    "guess = model.infer(x)[0]\n",
    "truth = \"HEY COMPUTER COULD YOU TURN THE LIGHTS ON IN THE KITCHEN PLEASE\"\n",
    "print(guess)\n",
    "print(tokenizer.DecodeIds(guess))\n",
    "print(tokenizer.EncodeAsIds(truth))\n",
    "print(truth)\n",
    "\n",
    "encoder_out = model.encoder.forward(x, T=None).detach().requires_grad_()\n",
    "print(encoder_out.shape)\n",
    "num_labels = encoder_out.shape[2]\n",
    "blank_index = num_labels-1\n",
    "T = torch.LongTensor([encoder_out.shape[1]])\n",
    "U = torch.LongTensor([ len(tokenizer.EncodeAsIds(truth)) ]) #torch.LongTensor([ len(guess) ])#\n",
    "y = torch.LongTensor([ tokenizer.EncodeAsIds(truth) ]) #torch.LongTensor([ guess ]) #\n",
    "decoder_out = torch.ones(batch_size, max(U)+1, num_labels).log_softmax(2).detach().requires_grad_()\n",
    "print(decoder_out.shape)\n",
    "print(y)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[ 26,  23, 464,  33,  86, 115,  38, 549,   5, 368,   3,  55,  20,   5,\n",
      "         379,   7,  81,   8,  10, 779]])\n",
      "loss: tensor(963.9097, grad_fn=<MeanBackward0>)\n",
      "encoder_out:\n",
      "tensor([[[-3.1079e+01, -3.1479e+01, -3.2192e+01,  ..., -2.7915e+01,\n",
      "          -1.6461e+01, -3.9934e-05],\n",
      "         [-3.5199e+01, -3.5653e+01, -3.5982e+01,  ..., -3.2546e+01,\n",
      "          -2.0299e+01, -3.8147e-06],\n",
      "         [-3.7666e+01, -3.8163e+01, -3.8327e+01,  ..., -3.5049e+01,\n",
      "          -2.1831e+01, -1.4305e-06],\n",
      "         ...,\n",
      "         [-3.4317e+01, -3.4587e+01, -3.4978e+01,  ..., -3.1293e+01,\n",
      "          -1.8083e+01, -5.7696e-05],\n",
      "         [-2.9255e+01, -2.9440e+01, -2.9596e+01,  ..., -2.7685e+01,\n",
      "          -1.5757e+01, -4.6111e-04],\n",
      "         [-2.4411e+01, -2.4522e+01, -2.4562e+01,  ..., -2.3631e+01,\n",
      "          -1.5108e+01, -2.9781e-03]]], requires_grad=True)\n",
      "encoder grad:\n",
      "tensor([[[-2.1835e-07, -1.7709e-10, -4.9841e-21,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-7.6187e-08, -1.7124e-11, -3.5939e-22,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-4.1892e-08, -5.6853e-12, -3.6842e-23,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.2742e-16,\n",
      "          -1.8666e-12, -1.6748e-09],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.8479e-16,\n",
      "          -2.3015e-11, -3.8361e-07],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0518e-14,\n",
      "          -4.4803e-10, -2.6313e-05]]])\n",
      "decoder_out:\n",
      "tensor([[[-6.9088, -6.9088, -6.9088,  ..., -6.9088, -6.9088, -6.9088],\n",
      "         [-6.9088, -6.9088, -6.9088,  ..., -6.9088, -6.9088, -6.9088],\n",
      "         [-6.9088, -6.9088, -6.9088,  ..., -6.9088, -6.9088, -6.9088],\n",
      "         ...,\n",
      "         [-6.9088, -6.9088, -6.9088,  ..., -6.9088, -6.9088, -6.9088],\n",
      "         [-6.9088, -6.9088, -6.9088,  ..., -6.9088, -6.9088, -6.9088],\n",
      "         [-6.9088, -6.9088, -6.9088,  ..., -6.9088, -6.9088, -6.9088]]],\n",
      "       requires_grad=True)\n",
      "decoder grad:\n",
      "tensor([[[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000, -24.0032],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,  -4.1976],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,  -5.8036],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,  -2.8196],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,  -5.0416],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000, -48.0010]]])\n"
     ]
    }
   ],
   "source": [
    "transducer_loss = TransducerLoss()\n",
    "log_probs = transducer_loss(encoder_out=encoder_out,decoder_out=decoder_out,targets=y,input_lengths=T,target_lengths=U,reduction=\"none\",blank=blank_index)\n",
    "loss = (-log_probs).mean()\n",
    "\n",
    "print(\"y:\", y)\n",
    "print(\"loss:\", loss)\n",
    "loss.backward()\n",
    "\n",
    "print(\"encoder_out:\")\n",
    "print(encoder_out)\n",
    "\n",
    "print(\"encoder grad:\")\n",
    "print(encoder_out.grad[:,:,y[0]].shape)\n",
    "print(encoder_out.grad[:,:,y[0]])\n",
    "del encoder_out.grad\n",
    "\n",
    "print(\"decoder_out:\")\n",
    "print(decoder_out)\n",
    "\n",
    "print(\"decoder grad:\")\n",
    "print(decoder_out.grad)\n",
    "del decoder_out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
