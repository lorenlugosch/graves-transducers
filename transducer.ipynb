{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransducerLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransducerLoss, self).__init__()\n",
    "        \n",
    "    def show_alignment(self, log_alpha):\n",
    "        plt.imshow(log_alpha.cpu().data.numpy().transpose(), origin=\"lower\"); plt.show()\n",
    "    \n",
    "    def compute_log_alpha_and_log_prob(self, encoder_out, decoder_out, y, blank):\n",
    "        \"\"\"\n",
    "        encoder_out: FloatTensor (T, #labels)\n",
    "        decoder_out: FloatTensor (U+1, #labels)\n",
    "        y: LongTensor (U,)\n",
    "        blank: int\n",
    "        \"\"\"\n",
    "        T = len(encoder_out)\n",
    "        U = len(y)\n",
    "        \n",
    "        log_alpha = torch.zeros(T, U+1) #[]\n",
    "        for t in range(T):\n",
    "            \n",
    "            for u in range(U + 1):\n",
    "                if u == 0:\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        log_alpha[t,u] = 0.\n",
    "                    \n",
    "                    else: #t > 0\n",
    "                        null_t_1_0 = encoder_out[t-1, blank] + decoder_out[0, blank]\n",
    "                        log_alpha[t,u] = log_alpha[t-1,u] + null_t_1_0\n",
    "                        \n",
    "                else: #u > 0\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        y_0_u_1 = encoder_out[t, y[u-1]] + decoder_out[u-1, y[u-1]]\n",
    "                        log_alpha[t,u] = log_alpha[t,u-1] + y_0_u_1\n",
    "                    \n",
    "                    else: #t > 0\n",
    "                        y_t_u_1 = encoder_out[t, y[u-1]] + decoder_out[u-1, y[u-1]]\n",
    "                        null_t_1_u = encoder_out[t-1, blank] + decoder_out[u, blank]\n",
    "                        \n",
    "                        log_alpha[t,u] = torch.logsumexp(torch.stack([\n",
    "                            log_alpha[t-1,u] + null_t_1_u,\n",
    "                            log_alpha[t,u-1] + y_t_u_1 \n",
    "                        ]), dim=0)\n",
    "        \n",
    "        null_T_1_U = encoder_out[T-1, blank] + decoder_out[U, blank]\n",
    "        log_p_y_x = log_alpha[T-1,U] + null_T_1_U\n",
    "        return log_alpha, log_p_y_x\n",
    "    \n",
    "    def forward_nonvectorized(self,encoder_out,decoder_out,targets,input_lengths,target_lengths,reduction=\"none\",blank=0):\n",
    "        \"\"\"\n",
    "        encoder_out: FloatTensor (N, max(input_lengths), #labels)\n",
    "        decoder_out: FloatTensor (N, max(target_lengths)+1, #labels)\n",
    "        targets: LongTensor (N, max(target_lengths))\n",
    "        input_lengths: LongTensor (N)\n",
    "        target_lengths: LongTensor (N)\n",
    "        reduction: \"none\", \"avg\"\n",
    "        blank: int\n",
    "        \"\"\"\n",
    "        batch_size = len(input_lengths)\n",
    "        log_probs = []\n",
    "        for i in range(0, batch_size):\n",
    "            encoder_out_ = encoder_out[i, :input_lengths[i], :]\n",
    "            decoder_out_ = decoder_out[i, :target_lengths[i]+1, :]\n",
    "            y = targets[i, :target_lengths[i]]\n",
    "            log_alpha, log_p_y_x = self.compute_log_alpha_and_log_prob(encoder_out_, decoder_out_, y, blank)\n",
    "            self.show_alignment(log_alpha)\n",
    "            log_probs.append(log_p_y_x)\n",
    "        log_probs = torch.stack(log_probs)\n",
    "        return log_probs\n",
    "        \n",
    "    def forward(self,encoder_out,decoder_out,targets,input_lengths,target_lengths,reduction=\"none\",blank=0):\n",
    "        \"\"\"\n",
    "        encoder_out: FloatTensor (N, max(input_lengths), #labels)\n",
    "        decoder_out: FloatTensor (N, max(target_lengths)+1, #labels)\n",
    "        targets: LongTensor (N, max(target_lengths))\n",
    "        input_lengths: LongTensor (N)\n",
    "        target_lengths: LongTensor (N)\n",
    "        reduction: \"none\", \"avg\"\n",
    "        blank: int\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = encoder_out.shape[0]\n",
    "        T_max = encoder_out.shape[1]\n",
    "        U_max = decoder_out.shape[1]\n",
    "        \n",
    "        log_alpha = torch.zeros(batch_size, T_max, U_max) #[]\n",
    "        for t in range(T_max):\n",
    "            \n",
    "            for u in range(U_max):\n",
    "                if u == 0:\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        log_alpha[:, t, u] = 0.\n",
    "                    \n",
    "                    else: #t > 0\n",
    "                        null_t_1_0 = encoder_out[:, t-1, blank] + decoder_out[:, 0, blank]\n",
    "                        log_alpha[:, t, u] = log_alpha[:, t-1, u] + null_t_1_0\n",
    "                        \n",
    "                else: #u > 0\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        y_0_u_1 = torch.gather(encoder_out[:, t], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1) + torch.gather(decoder_out[:, u-1], dim=1, index=y[:,u-1].view(-1,1)).reshape(-1)\n",
    "                        log_alpha[:, t, u] = log_alpha[:,t,u-1] + y_0_u_1\n",
    "                    \n",
    "                    else: #t > 0\n",
    "                        y_t_u_1 = torch.gather(encoder_out[:, t], dim=1, index=y[:,u-1].view(-1,1)).reshape(-1) + torch.gather(decoder_out[:, u-1], dim=1, index=y[:,u-1].view(-1,1)).reshape(-1)\n",
    "                        null_t_1_u = encoder_out[:, t-1, blank] + decoder_out[:, u, blank]\n",
    "                        \n",
    "                        log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
    "                            log_alpha[:, t-1, u] + null_t_1_u,\n",
    "                            log_alpha[:, t, u-1] + y_t_u_1 \n",
    "                        ]), dim=0)\n",
    "        \n",
    "        log_probs = []\n",
    "        for i in range(batch_size):\n",
    "            T = input_lengths[i]\n",
    "            U = target_lengths[i]\n",
    "            null_T_1_U = encoder_out[i, T-1, blank] + decoder_out[i, U, blank]\n",
    "            log_p_y_x = log_alpha[i, T-1, U] + null_T_1_U\n",
    "            log_probs.append(log_p_y_x)\n",
    "        \n",
    "        log_probs = torch.stack(log_probs)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 5])\n",
      "torch.Size([1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "num_labels = 5\n",
    "blank_index = num_labels-1 # last output = blank\n",
    "pad = 0 # can't be -1 due to gather()\n",
    "\n",
    "# batch_size = 2\n",
    "# T = torch.LongTensor([4,4])\n",
    "# U = torch.LongTensor([3,2])\n",
    "# y = torch.LongTensor([ [1,2,1], [2,1,pad] ])\n",
    "\n",
    "batch_size = 1\n",
    "T = torch.LongTensor([4])\n",
    "U = torch.LongTensor([3])\n",
    "y = torch.LongTensor([ [1,2,1] ])\n",
    "\n",
    "\n",
    "encoder_out = torch.randn(batch_size, max(T), num_labels).log_softmax(2).detach().requires_grad_()\n",
    "decoder_out = torch.randn(batch_size, max(U)+1, num_labels).log_softmax(2).detach().requires_grad_()\n",
    "print(encoder_out.shape)\n",
    "print(decoder_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y[:,u-1].view(-1,1) tensor([[1]])\n",
      "y[:,u-1].view(-1,1) tensor([[2]])\n",
      "y[:,u-1].view(-1,1) tensor([[1]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[1, 2, 1]])\n",
      "loss (non-vectorized): tensor(23.0253, grad_fn=<MeanBackward0>)\n",
      "loss (vectorized): tensor(23.0253, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "transducer_loss = TransducerLoss()\n",
    "log_probs = transducer_loss.forward(encoder_out=encoder_out,decoder_out=decoder_out,targets=y,input_lengths=T,target_lengths=U,reduction=\"none\",blank=blank_index)\n",
    "loss_vectorized = (-log_probs).mean()\n",
    "log_probs = transducer_loss.forward_nonvectorized(encoder_out=encoder_out,decoder_out=decoder_out,targets=y,input_lengths=T,target_lengths=U,reduction=\"none\",blank=blank_index)\n",
    "loss_nonvectorized = (-log_probs).mean()\n",
    "\n",
    "print(\"y:\", y)\n",
    "print(\"loss (non-vectorized):\", loss_nonvectorized)\n",
    "print(\"loss (vectorized):\", loss_vectorized)\n",
    "\n",
    "# loss.backward()\n",
    "\n",
    "# print(\"encoder_out:\")\n",
    "# print(encoder_out)\n",
    "\n",
    "# print(\"encoder grad:\")\n",
    "# print(encoder_out.grad[:,:,y[0]].shape)\n",
    "# plt.imshow(encoder_out.grad[0,:,y[0]].transpose(0,1).detach()); plt.show()\n",
    "# print(encoder_out.grad[:,:,y[0]])\n",
    "# del encoder_out.grad\n",
    "\n",
    "# print(\"decoder_out:\")\n",
    "# print(decoder_out)\n",
    "\n",
    "# print(\"decoder grad:\")\n",
    "# print(decoder_out.grad)\n",
    "# del decoder_out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTCModel(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): ComputeFBANK()\n",
      "      (1): Conv(\n",
      "        (conv): Conv1d(80, 512, kernel_size=(11,), stride=(2,))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.125)\n",
      "      (3): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (4): RNNOutputSelect()\n",
      "      (5): Dropout(p=0.2, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (7): LeakyReLU(negative_slope=0.125)\n",
      "      (8): Downsample()\n",
      "      (9): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (10): RNNOutputSelect()\n",
      "      (11): Dropout(p=0.2, inplace=False)\n",
      "      (12): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (13): LeakyReLU(negative_slope=0.125)\n",
      "      (14): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (15): RNNOutputSelect()\n",
      "      (16): Dropout(p=0.2, inplace=False)\n",
      "      (17): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (18): LeakyReLU(negative_slope=0.125)\n",
      "      (19): Linear(in_features=512, out_features=1001, bias=True)\n",
      "      (20): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[26, 464, 33, 86, 115, 8, 86, 10, 9, 14, 3, 55, 20, 5, 379, 7, 81, 8, 10, 358, 8]\n",
      "HE COMPUTER COULDETERNALS ON IN THE KITCHENPLEE\n",
      "[26, 23, 464, 33, 86, 115, 38, 549, 5, 368, 3, 55, 20, 5, 379, 7, 81, 8, 10, 779]\n",
      "HEY COMPUTER COULD YOU TURN THE LIGHTS ON IN THE KITCHEN PLEASE\n",
      "torch.Size([1, 90, 1001])\n",
      "torch.Size([1, 21, 1001])\n",
      "tensor([[ 26,  23, 464,  33,  86, 115,  38, 549,   5, 368,   3,  55,  20,   5,\n",
      "         379,   7,  81,   8,  10, 779]])\n",
      "tensor([20])\n"
     ]
    }
   ],
   "source": [
    "# use pre-trained CTC model\n",
    "from models import CTCModel\n",
    "from data import read_config\n",
    "import sentencepiece as spm\n",
    "import soundfile as sf\n",
    "\n",
    "config = read_config(\"experiments/80_mel.cfg\")\n",
    "model = CTCModel(config=config).eval()\n",
    "model.load_pretrained(\"experiments/80_mel/training/best_model.pth\")\n",
    "print(model)\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(\"tokenizer_1000_tokens.model\")\n",
    "\n",
    "x,fs = sf.read(\"../end-to-end-SLU/test.wav\")\n",
    "x = torch.tensor(x).unsqueeze(0).float()\n",
    "\n",
    "guess = model.infer(x)[0]\n",
    "truth = \"HEY COMPUTER COULD YOU TURN THE LIGHTS ON IN THE KITCHEN PLEASE\"\n",
    "print(guess)\n",
    "print(tokenizer.DecodeIds(guess))\n",
    "print(tokenizer.EncodeAsIds(truth))\n",
    "print(truth)\n",
    "\n",
    "encoder_out = model.encoder.forward(x, T=None).detach().requires_grad_()\n",
    "print(encoder_out.shape)\n",
    "num_labels = encoder_out.shape[2]\n",
    "blank_index = num_labels-1\n",
    "T = torch.LongTensor([encoder_out.shape[1]])\n",
    "U = torch.LongTensor([ len(tokenizer.EncodeAsIds(truth)) ]) #torch.LongTensor([ len(guess) ])#\n",
    "y = torch.LongTensor([ tokenizer.EncodeAsIds(truth) ]) #torch.LongTensor([ guess ]) #\n",
    "decoder_out = torch.ones(batch_size, max(U)+1, num_labels).log_softmax(2).detach().requires_grad_()\n",
    "print(decoder_out.shape)\n",
    "print(y)\n",
    "print(U)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
